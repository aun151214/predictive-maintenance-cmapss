ğŸ”§ Predictive Maintenance with NASA C-MAPSS Dataset

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python](https://img.shields.io/badge/python-3.11-blue.svg) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg) ![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3-green.svg) ![Status](https://img.shields.io/badge/Status-Completed-brightgreen.svg)  


This project implements predictive maintenance using the NASA C-MAPSS Turbofan Engine Degradation Datasets (FD001â€“FD004).
The goal is to predict the Remaining Useful Life (RUL) of engines before failure.

We benchmark multiple models, from classical ML to deep learning (LSTM, GRU, Transformer).

ğŸ“‚ Project Structure
predictive-maintenance-cmapss/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original C-MAPSS dataset (train/test/RUL txt files)
â”‚   â””â”€â”€ processed/        # Preprocessed pickles (.pkl) generated by preprocessing
â”‚
â”œâ”€â”€ models/               # Saved trained models (.keras)
â”œâ”€â”€ results/              # Model evaluation outputs (CSV, plots, reports)
â”‚   â”œâ”€â”€ final_report.pdf  # Auto-generated summary report
â”‚   â””â”€â”€ final_report.md   # Markdown summary of results
â”‚
â”œâ”€â”€ notebooks/            # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ 01_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_baseline_models.ipynb
â”‚   â”œâ”€â”€ 04_deep_learning_models.ipynb
â”‚   â”œâ”€â”€ 05_other_dl_models.ipynb
â”‚   â””â”€â”€ 07_transformer_fd001.ipynb
â”‚
â”œâ”€â”€ src/                  # Training, evaluation, preprocessing scripts
â”‚   â”œâ”€â”€ 02_preprocessing.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ aggregate_results.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ run_all.bat           # Full automation: preprocess â†’ train â†’ evaluate â†’ report
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


ğŸ“Š Results

Performance is reported across all four subsets (FD001â€“FD004):

| Model       | Dataset | RMSE   | MAE   | RÂ²     |
| ----------- | ------- | ------ | ----- | ------ |
| LSTM        | FD001   | 63.61  | 50.67 | -0.358 |
| LSTM        | FD002   | 68.73  | 54.47 | -0.339 |
| LSTM        | FD003   | 87.25  | 63.52 | -0.162 |
| LSTM        | FD004   | 102.05 | 76.52 | -0.311 |
| GRU         | FD001   | 63.62  | 50.67 | -0.358 |
| GRU         | FD002   | 68.37  | 54.17 | -0.325 |
| GRU         | FD003   | 87.21  | 63.49 | -0.161 |
| GRU         | FD004   | 102.11 | 76.57 | -0.313 |
| Transformer | FD001   | 47.59  | 36.94 | 0.240  |
| Transformer | FD002   | 52.94  | 41.11 | 0.206  |
| Transformer | FD003   | 69.67  | 53.07 | 0.259  |
| Transformer | FD004   | 80.61  | 59.30 | 0.182  |


ğŸ“„ See the final_report.pdf for full details with tables & charts.

ğŸ“¥ Dataset Setup

The dataset comes from NASAâ€™s C-MAPSS Turbofan Engine Degradation Simulation.

ğŸ”— Download here: NASA Prognostics Data Repository

After downloading:

Extract files into data/raw/

data/raw/
â”œâ”€â”€ train_FD001.txt
â”œâ”€â”€ test_FD001.txt
â”œâ”€â”€ RUL_FD001.txt
â”œâ”€â”€ train_FD002.txt
â”œâ”€â”€ ...


Run preprocessing:

python src/02_preprocessing.py


This will generate .pkl files under data/processed/.

âš™ï¸ Installation
# Clone repo
git clone https://github.com/aun151214/predictive-maintenance-cmapss.git
cd predictive-maintenance-cmapss

# Create environment
python -m venv .venv
.venv\Scripts\activate   # Windows
# source .venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

ğŸš€ Usage
ğŸ”¹ Train a Model
python src/train.py --model lstm --dataset FD001 --epochs 100 --batch_size 64
python src/train.py --model gru --dataset FD002 --epochs 100
python src/train.py --model transformer --dataset FD004 --epochs 100

ğŸ”¹ Evaluate a Model
python src/evaluate.py --model lstm --dataset FD001

ğŸ”¹ Run Full Pipeline (all models, all datasets, auto-report)
.\run_all.bat


This will:

Preprocess datasets

Train & evaluate all models on FD001â€“FD004

Save trained models in models/

Save results in results/

Auto-generate final_report.pdf & final_report.md

ğŸ“ˆ Key Insights

Transformer performed best overall on FD001â€“FD004 (positive RÂ²).

LSTM and GRU underperformed on FD002â€“FD004 in this run, suggesting tuning/data augmentation needed.

Pipeline is fully automated â†’ reproducible for any new dataset.

ğŸ“œ License

This project is released under the MIT License.
